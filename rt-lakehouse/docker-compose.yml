version: '3.8'

services:
  # DuckDB + Delta Lake data warehouse
  duckdb:
    image: duckdb/duckdb:latest
    container_name: rt_duckdb
    volumes:
      - ./data/duckdb:/data
      - ./data/delta:/delta
    ports:
      - "5432:5432"
    environment:
      - DUCKDB_DATABASE=/data/lakehouse.db
    restart: unless-stopped

  # Qdrant vector database
  qdrant:
    image: qdrant/qdrant:latest
    container_name: rt_qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./data/qdrant:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped

  # Apache Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: rt_zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: rt_kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    restart: unless-stopped

  # Event producer
  producer:
    build:
      context: .
      dockerfile: services/Dockerfile.producer
    container_name: rt_producer
    depends_on:
      - kafka
    environment:
      - KAFKA_BOOTSTRAP=kafka:29092
      - KAFKA_TOPIC=ecommerce_events
      - EVENTS_PER_SEC=100
    restart: unless-stopped

  # Spark streaming (Bronze -> Silver -> Gold)
  spark-streaming:
    build:
      context: .
      dockerfile: services/Dockerfile.spark
    container_name: rt_spark
    depends_on:
      - kafka
      - duckdb
    volumes:
      - ./data/delta:/delta
      - ./data/checkpoints:/checkpoints
    environment:
      - KAFKA_BOOTSTRAP=kafka:29092
      - KAFKA_TOPIC=ecommerce_events
      - DUCKDB_PATH=/delta/lakehouse.db
      - DELTA_PATH=/delta
    restart: unless-stopped

  # LLM Assistant API
  assistant-api:
    build:
      context: .
      dockerfile: services/Dockerfile.assistant
    container_name: rt_assistant
    depends_on:
      - duckdb
      - qdrant
    ports:
      - "8000:8000"
    environment:
      - DUCKDB_PATH=/delta/lakehouse.db
      - QDRANT_URL=http://qdrant:6333
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./data/delta:/delta
    restart: unless-stopped

  # Frontend Dashboard
  frontend:
    build:
      context: .
      dockerfile: services/Dockerfile.frontend
    container_name: rt_frontend
    depends_on:
      - assistant-api
      - qdrant
      - duckdb
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
      - REACT_APP_QDRANT_URL=http://localhost:6333
    restart: unless-stopped

  # Monitoring & Metrics
  monitoring:
    build:
      context: .
      dockerfile: services/Dockerfile.monitoring
    container_name: rt_monitoring
    depends_on:
      - kafka
      - duckdb
      - qdrant
      - assistant-api
    ports:
      - "8080:8080"
    environment:
      - KAFKA_URL=kafka:29092
      - DUCKDB_PATH=/delta/lakehouse.db
      - QDRANT_URL=http://qdrant:6333
      - ASSISTANT_URL=http://assistant-api:8000
    volumes:
      - ./data/delta:/delta
    restart: unless-stopped

volumes:
  duckdb_data:
  qdrant_data:
  delta_data:
  checkpoints:

networks:
  default:
    name: rt_lakehouse
