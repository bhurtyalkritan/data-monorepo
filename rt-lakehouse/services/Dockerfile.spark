FROM apache/spark:3.5.1-scala2.12-java11-python3-ubuntu

USER root

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Install Python packages
RUN pip install --no-cache-dir \
    delta-spark==3.2.0 \
    pyspark==3.5.1 \
    duckdb==0.10.0 \
    kafka-python==2.0.2

# Download Kafka connector JARs and dependencies
RUN wget -O /opt/spark/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar \
    https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.1/spark-sql-kafka-0-10_2.12-3.5.1.jar && \
    wget -O /opt/spark/jars/kafka-clients-3.5.1.jar \
    https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.5.1/kafka-clients-3.5.1.jar && \
    wget -O /opt/spark/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar \
    https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.5.1/spark-token-provider-kafka-0-10_2.12-3.5.1.jar && \
    wget -O /opt/spark/jars/commons-pool2-2.11.1.jar \
    https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar

# Copy Spark streaming code
COPY pipelines/ /app/pipelines/
COPY services/spark_runner.py /app/

WORKDIR /app

# Set Spark memory configuration
ENV SPARK_DRIVER_MEMORY=${SPARK_DRIVER_MEMORY:-4g}
ENV SPARK_EXECUTOR_MEMORY=${SPARK_EXECUTOR_MEMORY:-4g}
ENV SPARK_DRIVER_MAX_RESULT_SIZE=${SPARK_DRIVER_MAX_RESULT_SIZE:-2g}

# Run streaming pipeline with proper Spark configuration
CMD ["python3", "spark_runner.py"]
